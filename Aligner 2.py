# import streamlit as st
# import pandas as pd
# import numpy as np
# import re
# import os
# from io import BytesIO
# from sklearn.metrics.pairwise import cosine_similarity
# from fastdtw import fastdtw
# from sentence_transformers import SentenceTransformer
# import torch
# from datetime import datetime
# import logging

# # é…ç½®æ—¥å¿—ç³»ç»Ÿ
# logging.basicConfig(level=logging.INFO)

# # è®¾ç½®é•œåƒç«™å¤‡ç”¨ï¼ˆå¦‚éœ€å¯ç”¨å–æ¶ˆæ³¨é‡Šï¼‰
# # os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'

# # ========== å·¥å…·å‡½æ•° ==========
# def split_sentences(text, lang):
#     """æ™ºèƒ½åˆ†å¥å‡½æ•°"""
#     split_patterns = {
#         "zh": r'([ã€‚ï¼ï¼Ÿ?ï¼])([^â€â€™])',
#         "en": r'([.!?])([â€™"])'
#     }
#     processed = re.sub(split_patterns[lang], r'\1\n\2', text)
#     return [s.strip() for s in re.split(r'\n+', processed) if s.strip()]

# @st.cache_data(show_spinner=False)
# def load_file(uploaded_file, default_path):
#     """å¸¦ç¼“å­˜çš„æ–‡ä»¶åŠ è½½"""
#     if uploaded_file:
#         return uploaded_file.read().decode("utf-8")
#     try:
#         with open(default_path, "r", encoding="utf-8") as f:
#             return f.read()
#     except FileNotFoundError:
#         return None

# # ========== æ ¸å¿ƒåŠŸèƒ½ ==========
# @st.cache_resource(show_spinner=False)
# def load_model(device="cpu"):
#     """å¸¦æ™ºèƒ½ç¼“å­˜çš„æ¨¡å‹åŠ è½½"""
#     try:
#         model = SentenceTransformer(
#             "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
#             device=device
#         )
#         logging.info(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ | è®¾å¤‡: {device.upper()}")
#         return model
#     except Exception as e:
#         logging.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
#         st.error(f"""
#             âŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥ï¼š
#             1. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸
#             2. å°è¯•å¯ç”¨é•œåƒç«™ï¼ˆå–æ¶ˆä»£ç ç¬¬15è¡Œæ³¨é‡Šï¼‰
#             3. é”™è¯¯è¯¦æƒ…ï¼š{str(e)}
#         """)
#         st.stop()

# def calculate_alignment(zh_sents, en_sents, use_gpu):
#     """æ‰§è¡Œå¯¹é½çš„æ ¸å¿ƒæµç¨‹"""
#     # åŠ¨æ€è®¾å¤‡é€‰æ‹©
#     device = "cuda" if use_gpu and torch.cuda.is_available() else "cpu"
#     model = load_model(device)
    
#     # ç”ŸæˆåµŒå…¥å‘é‡
#     with st.spinner("ğŸ” ç”Ÿæˆæ–‡æœ¬åµŒå…¥..."):
#         zh_embeddings = model.encode(zh_sents)
#         en_embeddings = model.encode(en_sents)

#     # ç›¸ä¼¼åº¦è®¡ç®—å‡½æ•°
#     def cosine_distance(a, b):
#         return 1 - cosine_similarity([a], [b])[0][0]

#     # æ‰§è¡ŒåŠ¨æ€æ—¶é—´è§„æ•´
#     with st.spinner("ğŸ”„ åŠ¨æ€æ—¶é—´è§„æ•´å¯¹é½ä¸­..."):
#         _, path = fastdtw(zh_embeddings, en_embeddings, 
#                          dist=cosine_distance, radius=3)

#     # æ„å»ºå¯¹é½ç»“æœ
#     aligned_pairs = []
#     last_zh, last_en = -1, -1
    
#     for i, j in path:
#         if i != last_zh and j != last_en:
#             aligned_pairs.append((zh_sents[i], en_sents[j]))
#             last_zh, last_en = i, j
#         elif i == last_zh:
#             aligned_pairs[-1] = (aligned_pairs[-1][0], 
#                                 aligned_pairs[-1][1] + " " + en_sents[j])
#             last_en = j
#         elif j == last_en:
#             aligned_pairs[-1] = (aligned_pairs[-1][0] + zh_sents[i], 
#                                 aligned_pairs[-1][1])
#             last_zh = i
#     return aligned_pairs

# # ========== ç•Œé¢ç»„ä»¶ ==========
# def main_interface():
#     """ä¸»ç•Œé¢å¸ƒå±€"""
#     st.title("ğŸŒ æ™ºèƒ½åŒè¯­å¯¹é½ç³»ç»Ÿ")
#     st.caption("ä¸“ä¸šçº§ä¸­è‹±æ–‡æ–‡æ¡£å¯¹é½å·¥å…· | æ”¯æŒGPUåŠ é€Ÿ")

#     # ä¾§è¾¹æ è®¾ç½®
#     with st.sidebar:
#         st.header("âš™ï¸ è®¾ç½®")
#         use_gpu = st.checkbox("å¯ç”¨GPUåŠ é€Ÿ", 
#                              value=torch.cuda.is_available(),
#                              help="éœ€è¦NVIDIAæ˜¾å¡å¹¶å®‰è£…CUDAé©±åŠ¨")
        
#         # if st.button("ğŸ”„ æ¸…ç©ºç¼“å­˜"):
#         #     st.cache_resource.clear()
#         #     st.cache_data.clear()
#         #     st.success("ç¼“å­˜å·²é‡ç½®ï¼")
        
#         st.markdown("---")
#         st.header("ğŸ“ æ–‡ä»¶ä¸Šä¼ ")
#         zh_file = st.file_uploader("ä¸Šä¼ ä¸­æ–‡æ–‡æ¡£", type=["txt"], key="zh")
#         en_file = st.file_uploader("ä¸Šä¼ è‹±æ–‡æ–‡æ¡£", type=["txt"], key="en")

#     # ä¸»å†…å®¹åŒº
#     col1, col2 = st.columns([3, 1])
    
#     with col1:
#         process_flow(zh_file, en_file, use_gpu)
    
#     with col2:
#         if st.session_state.get("processed"):
#             export_options()

# # ========== å¤„ç†æµç¨‹ ==========
# def process_flow(zh_file, en_file, use_gpu):
#     """å¤„ç†æµç¨‹æ§åˆ¶"""
#     zh_text = load_file(zh_file, "zn.txt")
#     en_text = load_file(en_file, "en.txt")

#     # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
#     if 'processed' not in st.session_state:
#         st.session_state.processed = False

#     # æ–‡ä»¶æ£€æŸ¥
#     if not zh_text or not en_text:
#         missing = []
#         if not zh_text: missing.append("ä¸­æ–‡æ–‡æ¡£")
#         if not en_text: missing.append("è‹±æ–‡æ–‡æ¡£")
#         st.error(f"âŒ ç¼ºå°‘ {' å’Œ '.join(missing)}")
#         return

#     # å¤„ç†æŒ‰é’®
#     if st.button("ğŸš€ å¼€å§‹å¤„ç†", use_container_width=True, type="primary"):
#         with st.status("ğŸ“Š å¤„ç†æµç¨‹", expanded=True) as status:
#             try:
#                 process_start = datetime.now()
                
#                 # åˆ†å¥å¤„ç†
#                 st.write("## é˜¶æ®µ 1/3ï¼šåˆ†å¥å¤„ç†")
#                 zh_sents = split_sentences(zh_text, "zh")
#                 en_sents = split_sentences(en_text, "en")
#                 st.write(f"- ä¸­æ–‡å¥å­æ•°ï¼š{len(zh_sents)}")
#                 st.write(f"- è‹±æ–‡å¥å­æ•°ï¼š{len(en_sents)}")

#                 # å¯¹é½å¤„ç†
#                 st.write("## é˜¶æ®µ 2/3ï¼šè¯­ä¹‰å¯¹é½")
#                 aligned = calculate_alignment(zh_sents, en_sents, use_gpu)
                
#                 # ç»“æœå­˜å‚¨
#                 st.write("## é˜¶æ®µ 3/3ï¼šç»“æœç”Ÿæˆ")
#                 st.session_state.df = pd.DataFrame(aligned, columns=["ä¸­æ–‡", "English"])
#                 st.session_state.aligned = aligned
#                 st.session_state.processed = True

#                 total_time = (datetime.now() - process_start).total_seconds()
#                 status.update(
#                     label=f"âœ… å¤„ç†å®Œæˆ | æ€»è€—æ—¶ {total_time:.2f}s",
#                     state="complete",
#                     expanded=False
#                 )

#             except Exception as e:
#                 status.update(label="âŒ å¤„ç†å¤±è´¥", state="error")
#                 st.error(f"é”™è¯¯è¯¦æƒ…ï¼š{str(e)}")
#                 st.stop()

#     # æ˜¾ç¤ºç»“æœ
#     if st.session_state.get("processed"):
#         st.success(f"æˆåŠŸå¯¹é½ {len(st.session_state.aligned)} å¯¹å¥å­")
#         st.dataframe(
#             st.session_state.df,
#             height=600,
#             use_container_width=True,
#             hide_index=True
#         )

# # ========== å¯¼å‡ºåŠŸèƒ½ ==========
# def export_options():
#     """å¯¼å‡ºé€‰é¡¹ç»„ä»¶"""
#     st.subheader("ğŸ“¥ å¯¼å‡ºé€‰é¡¹")
#     export_format = st.radio(
#         "é€‰æ‹©æ ¼å¼",
#         ["Excel", "CSV", "TXT", "HTML", "Markdown"],
#         index=0,
#         label_visibility="collapsed"
#     )
    
#     buffer = BytesIO()
#     df = st.session_state.df
    
#     # ç”Ÿæˆæ–‡ä»¶å†…å®¹
#     if export_format == "Excel":
#         with pd.ExcelWriter(buffer, engine='xlsxwriter') as writer:
#             df.to_excel(writer, index=False)
#         mime_type = "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
#         ext = "xlsx"
#     elif export_format == "CSV":
#         buffer.write(df.to_csv(index=False, encoding='utf-8-sig').encode('utf-8'))
#         mime_type = "text/csv"
#         ext = "csv"
#     elif export_format == "TXT":
#         content = "\n".join([f"{zh}\t{en}" for zh, en in st.session_state.aligned])
#         buffer.write(content.encode("utf-8"))
#         mime_type = "text/plain"
#         ext = "txt"
#     elif export_format == "HTML":
#         buffer.write(df.to_html(index=False, border=0).encode("utf-8"))
#         mime_type = "text/html"
#         ext = "html"
#     elif export_format == "Markdown":
#         buffer.write(df.to_markdown(index=False).encode("utf-8"))
#         mime_type = "text/markdown"
#         ext = "md"

#     # ä¸‹è½½æŒ‰é’®
#     st.download_button(
#         label=f"ä¸‹è½½ {export_format} æ–‡ä»¶",
#         data=buffer.getvalue(),
#         file_name=f"aligned_text.{ext}",
#         mime=mime_type,
#         use_container_width=True
#     )

# # ========== ä¸»ç¨‹åº ==========
# if __name__ == '__main__':
#     from streamlit.web import cli as stcli
#     from streamlit import runtime
#     import sys
#     st.set_page_config(
#         page_title="æ™ºèƒ½åŒè¯­å¯¹é½ç³»ç»Ÿ",
#         page_icon="ğŸŒ",
#         layout="wide",
#         initial_sidebar_state="expanded"
#     )
    
#     # éšè—é»˜è®¤çš„æ±‰å ¡èœå•
#     hide_menu_style = """
#         <style>
#         #MainMenu {visibility: hidden;}
#         footer {visibility: hidden;}
#         </style>
#     """
#     st.markdown(hide_menu_style, unsafe_allow_html=True)
#     if runtime.exists():
#         main_interface()
#     else:
#         sys.argv = ["streamlit", "run", sys.argv[0]]
#         sys.exit(stcli.main())

import streamlit as st
import pandas as pd
import numpy as np
import re
import os
from io import BytesIO
from sklearn.metrics.pairwise import cosine_similarity
from fastdtw import fastdtw
from sentence_transformers import SentenceTransformer
import torch
from datetime import datetime
import logging
import markdown  # æ–°å¢markdownå¤„ç†

# é…ç½®æ—¥å¿—ç³»ç»Ÿ
logging.basicConfig(level=logging.INFO)

# è®¾ç½®é•œåƒç«™å¤‡ç”¨ï¼ˆå¦‚éœ€å¯ç”¨å–æ¶ˆæ³¨é‡Šï¼‰
os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'

# ========== å·¥å…·å‡½æ•° ==========
def split_sentences(text, lang):
    """å¤šè¯­è¨€åˆ†å¥å‡½æ•°"""
    lang_rules = {
        "zh": r'([ã€‚ï¼ï¼Ÿ?ï¼])([^â€â€™])',
        "en": r'([.!?])([â€™"])',
        "ja": r'([ã€‚ï¼ï¼Ÿ?ï¼])',
        "eu": r'([.!?])',
    }
    pattern = lang_rules.get(lang, lang_rules["en"])
    processed = re.sub(pattern, r'\1\n', text)
    return [s.strip() for s in re.split(r'\n+', processed) if s.strip()]

@st.cache_data(show_spinner=False)
def load_file(uploaded_file, default_path):
    """å¸¦ç¼“å­˜çš„æ–‡ä»¶åŠ è½½"""
    if uploaded_file:
        return uploaded_file.read().decode("utf-8")
    try:
        with open(default_path, "r", encoding="utf-8") as f:
            return f.read()
    except FileNotFoundError:
        return None

# ========== æ ¸å¿ƒåŠŸèƒ½ ==========
@st.cache_resource(show_spinner=False)
def load_model(device="cpu"):
    """å¸¦æ™ºèƒ½ç¼“å­˜çš„æ¨¡å‹åŠ è½½"""
    try:
        model = SentenceTransformer(
            "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
            device=device
        )
        logging.info(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ | è®¾å¤‡: {device.upper()}")
        return model
    except Exception as e:
        logging.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
        st.error(f"""
            âŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥ï¼š
            1. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸
            2. å°è¯•å¯ç”¨é•œåƒç«™ï¼ˆå–æ¶ˆä»£ç ç¬¬15è¡Œæ³¨é‡Šï¼‰
            3. é”™è¯¯è¯¦æƒ…ï¼š{str(e)}
        """)
        st.stop()

def calculate_alignment(sents_a, sents_b, use_gpu):
    """æ‰§è¡Œå¯¹é½çš„æ ¸å¿ƒæµç¨‹"""
    # åŠ¨æ€è®¾å¤‡é€‰æ‹©
    device = "cuda" if use_gpu and torch.cuda.is_available() else "cpu"
    model = load_model(device)
    
    # ç”ŸæˆåµŒå…¥å‘é‡
    with st.spinner("ğŸ” ç”Ÿæˆæ–‡æœ¬åµŒå…¥..."):
        embeddings_a = model.encode(sents_a)
        embeddings_b = model.encode(sents_b)

    # ç›¸ä¼¼åº¦è®¡ç®—å‡½æ•°
    def cosine_distance(a, b):
        return 1 - cosine_similarity([a], [b])[0][0]

    # æ‰§è¡ŒåŠ¨æ€æ—¶é—´è§„æ•´
    with st.spinner("ğŸ”„ åŠ¨æ€æ—¶é—´è§„æ•´å¯¹é½ä¸­..."):
        _, path = fastdtw(embeddings_a, embeddings_b, 
                         dist=cosine_distance, radius=3)

    # æ„å»ºå¯¹é½ç»“æœ
    aligned_pairs = []
    last_a, last_b = -1, -1
    
    for i, j in path:
        if i != last_a and j != last_b:
            aligned_pairs.append((sents_a[i], sents_b[j]))
            last_a, last_b = i, j
        elif i == last_a:
            aligned_pairs[-1] = (aligned_pairs[-1][0], 
                                aligned_pairs[-1][1] + " " + sents_b[j])
            last_b = j
        elif j == last_b:
            aligned_pairs[-1] = (aligned_pairs[-1][0] + sents_a[i], 
                                aligned_pairs[-1][1])
            last_a = i
    return aligned_pairs

# ========== ç•Œé¢ç»„ä»¶ ==========
def main_interface():
    """ä¸»ç•Œé¢å¸ƒå±€"""
    st.title("ğŸŒ æ™ºèƒ½å¤šè¯­è¨€å¯¹é½ç³»ç»Ÿ")
    st.caption("ä¸“ä¸šçº§å¤šè¯­è¨€æ–‡æ¡£å¯¹é½å·¥å…· | æ”¯æŒGPUåŠ é€Ÿ")

    # ä¾§è¾¹æ è®¾ç½®
    with st.sidebar:
        st.header("âš™ï¸ è®¾ç½®")
        use_gpu = st.checkbox("å¯ç”¨GPUåŠ é€Ÿ", 
                             value=torch.cuda.is_available(),
                             help="éœ€è¦NVIDIAæ˜¾å¡å¹¶å®‰è£…CUDAé©±åŠ¨")
        
        st.markdown("---")
        st.header("ğŸ“ æ–‡ä»¶ä¸Šä¼ ")
        col1, col2 = st.columns(2)
        with col1:
            lang_a = st.selectbox("è¯­è¨€A", ["zh", "en", "ja", "eu"], index=0)
            file_a = st.file_uploader(f"ä¸Šä¼ {lang_a}æ–‡æ¡£", type=["txt", "md"], key="a")
        with col2:
            lang_b = st.selectbox("è¯­è¨€B", ["en", "zh", "ja", "eu"], index=0)
            file_b = st.file_uploader(f"ä¸Šä¼ {lang_b}æ–‡æ¡£", type=["txt", "md"], key="b")

    # ä¸»å†…å®¹åŒº
    col1, col2 = st.columns([3, 1])
    
    with col1:
        process_flow(file_a, file_b, lang_a, lang_b, use_gpu)
    
    with col2:
        if st.session_state.get("processed"):
            export_options()

# ========== å¤„ç†æµç¨‹ ==========
def process_flow(file_a, file_b, lang_a, lang_b, use_gpu):
    """å¤„ç†æµç¨‹æ§åˆ¶"""
    text_a = load_file(file_a, "a.txt")
    text_b = load_file(file_b, "b.txt")

    # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
    if 'processed' not in st.session_state:
        st.session_state.processed = False

    # æ–‡ä»¶æ£€æŸ¥
    if not text_a or not text_b:
        missing = []
        if not text_a: missing.append(f"{lang_a}æ–‡æ¡£")
        if not text_b: missing.append(f"{lang_b}æ–‡æ¡£")
        st.error(f"âŒ ç¼ºå°‘ {' å’Œ '.join(missing)}")
        return

    # å¤„ç†æŒ‰é’®
    if st.button("ğŸš€ å¼€å§‹å¤„ç†", use_container_width=True, type="primary"):
        with st.status("ğŸ“Š å¤„ç†æµç¨‹", expanded=True) as status:
            try:
                process_start = datetime.now()
                
                # åˆ†å¥å¤„ç†
                st.write("## é˜¶æ®µ 1/3ï¼šåˆ†å¥å¤„ç†")
                sents_a = split_sentences(text_a, lang_a)
                sents_b = split_sentences(text_b, lang_b)
                st.write(f"- {lang_a}å¥å­æ•°ï¼š{len(sents_a)}")
                st.write(f"- {lang_b}å¥å­æ•°ï¼š{len(sents_b)}")

                # å¯¹é½å¤„ç†
                st.write("## é˜¶æ®µ 2/3ï¼šè¯­ä¹‰å¯¹é½")
                aligned = calculate_alignment(sents_a, sents_b, use_gpu)
                
                # ç»“æœå­˜å‚¨
                st.write("## é˜¶æ®µ 3/3ï¼šç»“æœç”Ÿæˆ")
                st.session_state.df = pd.DataFrame(aligned, columns=[lang_a.upper(), lang_b.upper()])
                st.session_state.aligned = aligned
                st.session_state.processed = True

                total_time = (datetime.now() - process_start).total_seconds()
                status.update(
                    label=f"âœ… å¤„ç†å®Œæˆ | æ€»è€—æ—¶ {total_time:.2f}s",
                    state="complete",
                    expanded=False
                )

            except Exception as e:
                status.update(label="âŒ å¤„ç†å¤±è´¥", state="error")
                st.error(f"é”™è¯¯è¯¦æƒ…ï¼š{str(e)}")
                st.stop()

    # æ˜¾ç¤ºç»“æœ
    if st.session_state.get("processed"):
        st.success(f"æˆåŠŸå¯¹é½ {len(st.session_state.aligned)} å¯¹å¥å­")
        st.dataframe(
            st.session_state.df,
            height=600,
            use_container_width=True,
            hide_index=True
        )

# ========== å¯¼å‡ºåŠŸèƒ½ ==========
def generate_html_content(df, format_type):
    """ç”Ÿæˆç¾è§‚çš„HTMLå†…å®¹"""
    css_style = """
    <style>
        .alignment-container {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            max-width: 1200px;
            margin: 20px auto;
            padding: 20px;
            background-color: #f9f9f9;
            border-radius: 10px;
            box-shadow: 0 0 10px rgba(0,0,0,0.1);
        }
        .pair-item {
            background: white;
            margin: 10px 0;
            padding: 15px;
            border-radius: 5px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.05);
        }
        .lang-col {
            padding: 10px;
            border-right: 1px solid #eee;
        }
        table {
            width: 100%;
            border-collapse: collapse;
            background: white;
        }
        th, td {
            padding: 12px;
            text-align: left;
            border-bottom: 1px solid #ddd;
        }
        th {
            background-color: #4CAF50;
            color: white;
        }
        tr:hover {background-color: #f5f5f5;}
    </style>
    """

    if format_type == "è¡¨æ ¼":
        table_html = df.to_html(index=False, border=0, classes="dataframe", escape=False)
        content = f"""
        <div class="alignment-container">
            <h2 style="color: #2c3e50; text-align: center;">å¤šè¯­è¨€å¯¹é½ç»“æœ</h2>
            {table_html}
        </div>
        """
    else:
        show_groups = st.checkbox("æ˜¾ç¤ºåˆ†ç»„ç¼–å·", value=False, 
                                help="æ˜¯å¦åœ¨æ¯å¯¹è¯‘æ–‡å‰æ˜¾ç¤º'ç¬¬Xç»„'çš„ç¼–å·")
        pairs_html = ""
        
        for idx, (a, b) in enumerate(st.session_state.aligned):
            a_html = markdown.markdown(a)
            b_html = markdown.markdown(b)
            
            group_header = f'<h4>ç¬¬{idx+1}ç»„</h4>' if show_groups else ""
            
            pairs_html += f"""
            <div class="pair-item">
                <div class="lang-col">
                    {group_header}
                    <div class="lang-a">{a_html}</div>
                </div>
                <div class="lang-col">
                    <div class="lang-b">{b_html}</div>
                </div>
            </div>
            """
            
        content = f"""
        <div class="alignment-container">
            <h2 style="color: #2c3e50; text-align: center;">å¤šè¯­è¨€å¯¹ç…§ç»“æœ</h2>
            {pairs_html}
        </div>
        """
    
    return f"<html><head>{css_style}</head><body>{content}</body></html>"
    # else:
    #     pairs_html = ""
        
    #     for idx, (a, b) in enumerate(st.session_state.aligned):
    #         # è½¬æ¢Markdownä¸ºHTML
    #         a_html = markdown.markdown(a)
    #         b_html = markdown.markdown(b)
            
    #         col = f'<h4>ç¬¬{idx+1}ç»„</h4>'
    #         pairs_html += f"""
    #         <div class="pair-item">
    #             <div class="lang-col">
    #                 {col}
    #                 <div class="lang-a">{a_html}</div>
    #             </div>
    #             <div class="lang-col">
    #                 <div class="lang-b">{b_html}</div>
    #             </div>
    #         </div>
    #         """
    #     content = f"""
    #     <div class="alignment-container">
    #         <h2 style="color: #2c3e50; text-align: center;">å¤šè¯­è¨€å¯¹ç…§ç»“æœ</h2>
    #         {pairs_html}
    #     </div>
    #     """
    
    # return f"<html><head>{css_style}</head><body>{content}</body></html>"

def export_options():
    """å¯¼å‡ºé€‰é¡¹ç»„ä»¶"""
    st.subheader("ğŸ“¥ å¯¼å‡ºé€‰é¡¹")
    export_format = st.radio(
        "é€‰æ‹©æ ¼å¼",
        ["Excel", "CSV", "TXT", "HTML", "Markdown"],
        index=0,
        label_visibility="collapsed"
    )
    
    if export_format == "HTML":
        html_format = st.radio(
            "HTMLæ ¼å¼",
            ["è¡¨æ ¼", "å¯¹ç…§"],
            horizontal=True,
            label_visibility="collapsed"
        )
    
    buffer = BytesIO()
    df = st.session_state.df
    
    # ç”Ÿæˆæ–‡ä»¶å†…å®¹
    if export_format == "Excel":
        with pd.ExcelWriter(buffer, engine='xlsxwriter') as writer:
            df.to_excel(writer, index=False)
        mime_type = "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        ext = "xlsx"
    elif export_format == "CSV":
        buffer.write(df.to_csv(index=False, encoding='utf-8-sig').encode('utf-8'))
        mime_type = "text/csv"
        ext = "csv"
    elif export_format == "TXT":
        content = "\n".join([f"{a}\t{b}" for a, b in st.session_state.aligned])
        buffer.write(content.encode("utf-8"))
        mime_type = "text/plain"
        ext = "txt"
    elif export_format == "HTML":
        html_content = generate_html_content(df, html_format)
        buffer.write(html_content.encode("utf-8"))
        mime_type = "text/html"
        ext = "html"
    elif export_format == "Markdown":
        buffer.write(df.to_markdown(index=False).encode("utf-8"))
        mime_type = "text/markdown"
        ext = "md"

    # ä¸‹è½½æŒ‰é’®
    st.download_button(
        label=f"ä¸‹è½½ {export_format} æ–‡ä»¶",
        data=buffer.getvalue(),
        file_name=f"aligned_text.{ext}",
        mime=mime_type,
        use_container_width=True
    )

# ========== ä¸»ç¨‹åº ==========
if __name__ == '__main__':
    from streamlit.web import cli as stcli
    from streamlit import runtime
    import sys
    st.set_page_config(
        page_title="æ™ºèƒ½å¤šè¯­è¨€å¯¹é½ç³»ç»Ÿ",
        page_icon="ğŸŒ",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    # éšè—é»˜è®¤çš„æ±‰å ¡èœå•
    hide_menu_style = """
        <style>
        #MainMenu {visibility: hidden;}
        footer {visibility: hidden;}
        </style>
    """
    st.markdown(hide_menu_style, unsafe_allow_html=True)
    if runtime.exists():
        main_interface()
    else:
        sys.argv = ["streamlit", "run", sys.argv[0]]
        sys.exit(stcli.main())